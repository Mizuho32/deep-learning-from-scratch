= ゼロからつくる Deep Learning

== 1章
Python

== 2章
パーセプトロン。AND, OR, XORの恒例のやつ。

== 3章
ニューラルネットワーク。

3.2.1より、パーセプトロンとニューラルネットワークの違いは活性化関数だけ、ということになっているらしい

softmaxの計算には注意。

Juliaではargmax(x)-1とする

== 4章

損失関数を定義して、損失が小さくなるように重みで微分して重みを最適化

== 5章
計算木が大変。
値が行列になった時に逆伝播する値をバッチの個数で割ったりsumしたりするところが直観に反する。
式を書けばわかる・・・?
